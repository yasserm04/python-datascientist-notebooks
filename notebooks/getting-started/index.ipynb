{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ed6134-fc8b-4845-94d4-3a3355357270",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Lino Galiana  \n",
    "2025-10-06\n",
    "\n",
    "> **Compétences à l’issue de ce chapitre**\n",
    ">\n",
    "> -   Comprendre pourquoi Python est devenu incontournable dans le domaine de la *data science* et du *data engineering*, notamment grâce à sa simplicité, sa lisibilité et son écosystème communautaire riche ;\n",
    "> -   Identifier la manière dont Python peut vous assister dans les différentes étapes d’un projet de valorisation de données : structuration, exploration, modélisation, communication de résultats… ;\n",
    "> -   Appréhender l’importance d’une démarche reproductible, rigoureuse et scientifique dans la conduite de projets de *data science* ou de *data engineering* et les moyens pour cela (*notebooks Jupyter*, open data, environnements standardisés…) ;\n",
    "> -   Comprendre l’objet et les partis-pris pédagogiques du cours ainsi que son fil conducteur.\n",
    "\n",
    "# 1. Introduction\n",
    "\n",
    "Ce cours rassemble l’ensemble du contenu du cours\n",
    "***Python pour la data science*** que je donne à l’[ENSAE](https://www.ensae.fr/courses/python-pour-le-data-scientist-pour-leconomiste/) depuis 2020[1]. Environ 190 élèves suivent ce cours chaque année. L’année 2024 a permis l’arrivée progressive d’une version anglophone équivalente à\n",
    "la version française visant à servir de cours d’introduction à la *data science* pour les instituts statistiques européens\n",
    "suite à un [appel à projets européen](https://cros.ec.europa.eu/dashboard/aiml4os).\n",
    "\n",
    "Ce site ([pythonds.linogaliana.fr/](https://pythonds.linogaliana.fr)) est le point d’entrée principal du cours. Il rassemble l’ensemble des contenus faits en cours dans le cadre de travaux pratiques ou proposés en complément à des fins de formation en continue. Ce cours est *open source*\n",
    "et j’accueille avec plaisir les suggestions d’amélioration sur [`Github` ](https://github.com/linogaliana/python-datascientist) ou par le biais des commentaires en bas de chaque page.\n",
    "\n",
    "`Python` étant un langage vivant et très dynamique, les pratiques évoluent et ce cours s’adapte en continu pour tenir compte de l’écosystème mouvant de la *data science*, en essayant néanmoins de distinguer les évolutions pérennes des pratiques des effets de mode.\n",
    "\n",
    "Quelques éléments supplémentaires sont disponibles dans\n",
    "les [slides introductives](https://slidespython.linogaliana.fr/). Des éléments plus avancés sont présents dans un autre cours consacré à la mise en production de projets *data science*\n",
    "que je donne avec Romain Avouac\n",
    "en dernière année de l’ENSAE ([ensae-reproductibilite.github.io/website](https://ensae-reproductibilite.github.io/website)).\n",
    "\n",
    "[1] Ce cours était auparavant donné par [Xavier Dupré](http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx3/td_2a.html)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a040c20-c9dd-47d0-90af-b6ec71cef11b",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><p>Dérouler les <em>slides</em> ou consulter celles-ci sur <a\n",
    "href=\"https://slidespython.linogaliana.fr/\">plein écran</a>{target=</p></summary>\n",
    "<div class=\"sourceCode\">\n",
    "<iframe class=\"sourceCode\" src=\"https://slidespython.linogaliana.fr/\"></iframe>\n",
    "\n",
    "</div>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d0af4b-32dc-4b9d-bb34-65ce5e17d735",
   "metadata": {},
   "source": [
    "> **Architecture du site web**\n",
    ">\n",
    "> Ce cours présente des tutoriels et des exercices complets qui peuvent être lus depuis ce site ou édités et testés dans un environnement interactif de type `Jupyter Notebook` (voir [prochain chapitre](../../content/getting-started/01_environment.qmd) pour plus de détails).\n",
    ">\n",
    "> Chaque page est structurée sous la forme d’un problème concret et présente la démarche générique pour résoudre ce problème général. Tous les exemples s’appuient sur de l’*open data* et sont reproductibles.\n",
    ">\n",
    "> Vous pouvez naviguer dans l’architecture du site via la table des matières ou par les liens vers le contenu antérieur ou postérieur à la fin de chaque page. Certaines parties, notamment celle consacrée à la modélisation, proposent des exemples fil-rouge pour illustrer la démarche, et les différentes approches possibles d’un même problème, de manière\n",
    "> plus extensive.\n",
    "\n",
    "# 2. Pourquoi faire du `Python`  ?\n",
    "\n",
    "`Python`, dont le logo assez reconnaissable prend la forme de ,\n",
    "est un langage qui a déjà plus de trente ans\n",
    "mais qui a connu, au cours de la décennie 2010, une\n",
    "nouvelle jeunesse du fait de l’engouement autour de\n",
    "la *data science*.\n",
    "\n",
    "`Python`, plus que tout autre\n",
    "langage informatique, réunit des communautés aussi\n",
    "diverses que des statisticiens, des développeurs,\n",
    "des gestionnaires\n",
    "d’applications ou d’infrastructures informatiques,\n",
    "des lycéens - `Python` est au programme du bac français\n",
    "depuis quelques années - ou des chercheurs\n",
    "dans des champs à la fois théoriques et appliqués.\n",
    "\n",
    "Contrairement à beaucoup de langages informatiques qui fédèrent\n",
    "une communauté assez homogène, `Python` est parvenu à réunir\n",
    "largement grâce à quelques principes centraux : la lisibilité\n",
    "du langage, la simplicité à utiliser des modules,\n",
    "la simplicité à l’associer à des langages plus performants\n",
    "pour certaines tâches données, l’énorme volume de documentation\n",
    "disponible en ligne…\n",
    "Être le deuxième meilleur langage pour réaliser telle ou telle\n",
    "tâche\n",
    "peut ainsi être une source de succès lorsque la concurrence ne dispose\n",
    "pas d’un éventail aussi large d’avantages.\n",
    "\n",
    "Le succès de `Python`, de par sa nature de\n",
    "langage couteau-suisse, est indissociable\n",
    "de l’émergence du profil du *data scientist*, profil\n",
    "capable de s’intégrer à différents niveaux dans la valorisation\n",
    "de données.\n",
    "Davenport et Patil (2012), dans la *Harvard Business Review*,\n",
    "ont ainsi pu parler du *“boulot le plus sexy du 21e siècle”*\n",
    "et ont pu, dix ans plus tard, faire un panorama complet de l’évolution\n",
    "des compétences attendues d’un *data scientist* dans\n",
    "la même revue (Davenport et Patil 2022). Ce ne sont d’ailleurs pas que les\n",
    "*data scientists* qui ont vocation à pratiquer `Python` ; dans le halo\n",
    "des emplois autour de la donnée (*data scientist*, *data engineer*, *ML engineer*…),\n",
    "`Python` fait office de tour de Babel permettant la communication entre ces\n",
    "différents profils interdépendants.\n",
    "\n",
    "La richesse de `Python` permet de l’utiliser dans toutes les phases du traitement de la donnée, de sa récupération et structuration à partir de\n",
    "sources diverses à sa valorisation.\n",
    "Par le prisme de la *data science*, nous verrons que `Python` est un très bon candidat pour assister les *data scientists* dans tous les aspects du travail quotidien leur permettant de tirer de la valeur de gisements hétérogènes de données. Ce cours a néanmoins l’ambition, peut-être illusoire, d’être plus qu’un énième cours d’introduction au langage `Python`: il s’agit plutôt d’un cours d’introduction à la *data science* s’appuyant sur `Python`. En fait, apprendre `Python` est un prétexte pour apprendre à avoir les bons réflexes quand on est confronté à un jeu de données.\n",
    "\n",
    "Ce cours introduit différents outils qui permettent de mettre en relation grâce à `Python` des données à des concepts théoriques issus de la statistique ou des sciences économiques et sociales. Néanmoins, ce cours va au-delà d’une simple introduction au langage et revient régulièrement sur les apports, mais aussi les limites, du langage pour répondre à des besoins opérationnels ou scientifiques.\n",
    "\n",
    "# 3. Pourquoi faire du `Python`  pour l’analyse de données ?\n",
    "\n",
    "Cette question est un peu différente car si `Python` est un langage commun pour découvrir la programmation informatique du fait de sa simplicité d’usage, comment se fait-il qu’il se soit imposé comme le langage dominant dans l’écosystème de la *data* et de l’IA ?\n",
    "\n",
    "`Python` est d’abord connu, dans le monde de la *data science*, pour avoir fourni très tôt les outils utiles à l’entraînement d’algorithmes de *machine learning*, avant même que cette approche devienne incontournable. Certes,\n",
    "le succès de [`Scikit Learn`](https://scikit-learn.org/stable/), de [`Tensorflow`](https://www.tensorflow.org/) ou plus récemment de [`PyTorch`](https://pytorch.org/) dans la communauté de la *data science* ont beaucoup contribué à l’adoption de `Python`[1]. Cependant,\n",
    "réduire `Python` à quelques librairies de *machine learning*\n",
    "serait réducteur tant il s’agit\n",
    "d’un véritable couteau-suisse pour les *data scientists*,\n",
    "les *social scientists*, les économistes ou plus généralement pour les praticiens de la donnée quelque soit leur champ d’application. La *success story* de `Python`\n",
    "n’est pas seulement le fait d’avoir proposé des librairies de *machine learning* à un moment adéquat: ce\n",
    "langage dispose de réels atouts pour de nouveaux praticiens de la donnée.\n",
    "\n",
    "L’intérêt de `Python` est son rôle central dans un\n",
    "écosystème plus large autour d’outils puissants, flexibles et *open-source*. Il appartient, comme le langage , à cette classe de langages pouvant servir au quotidien pour des tâches très diversifiées. Dans de nombreux domaines explorés dans ce cours, `Python` est, de loin, le langage informatique proposant l’écosystème le plus complet et le plus simple d’accès. Contrairement à d’autres langages très populaires, notamment `JavaScript` ou `Rust`, la courbe d’appentissage de `Python` est très légère et on peut rapidement être opérationnel et produire du code de qualité, si on a les bons réflexes (que ce cours, ainsi que celui de [mise en production](https://ensae-reproductibilite.github.io/), ambitionnent de donner).\n",
    "\n",
    "En plus des projets d’IA (<a href=\"#nte-ia\" class=\"quarto-xref\">Note 3.1</a>), `Python` est\n",
    "incontournable dès lors qu’on désire récupérer des données par le biais d’API ou de *web scraping*[2], deux approches que nous explorerons dans la première partie du cours. Dans les domaines de l’analyse de données tabulaires[3], de la publication de contenu web ou de la production de graphiques, `Python` présente un écosystème\n",
    "de plus en plus similaire à du fait de l’investissement croissant de [`Posit`](https://posit.co/) et sa traduction en `Python` des librairies qui ont fait le succès de dans le domaine de l’analyse de données ([ggplot](https://ggplot2.tidyverse.org/) notamment)\n",
    "\n",
    "> **Note 3.1: Pourquoi parler si peu d’IA dans un cours de `Python` ?**\n",
    ">\n",
    "> Bien qu’une partie conséquente de ce cours évoque les problématiques de *machine learning* et d’algorithmie, je rechigne généralement à rentrer dans la mode, particulièrement forte depuis fin 2022 et la sortie de `ChatGPT`, de tout dénommer IA.\n",
    ">\n",
    "> En premier lieu car le terme est souvent mal défini, galvaudé et instrumentalisé par des acteurs qui profitent de sa charge symbolique forte, lié à notre imaginaire de la science fiction, pour vendre un produit “miracle” ou au contraire activer nos peurs.\n",
    ">\n",
    "> Mais aussi car ce terme recouvre énormément de méthodes potentielles si on accepte une définition large. Les parties modélisation et NLP de ce cours, celles les plus proches du sujet IA, se concentrent sur les méthodes d’apprentissage. Si on reprend les définitions suivantes Russell et Norvig (2020) ou de l’[IA Act Européen](https://artificialintelligenceact.eu/fr/article/3/), on peut faire rentrer beaucoup plus que ces méthodes dans le concept d’intelligence artificielle:\n",
    ">\n",
    "> > « L’étude des agents \\[intelligents\\] qui reçoivent des perceptions de l’environnement et agissent. Chacun de ces agents est mis en oeuvre par une fonction qui associe les perceptions aux actions, et nous couvrons différentes manières de de représenter ces fonctions, telles que les systèmes de production, les agents réactifs, les planificateurs logiques, les réseaux de neurones et les systèmes de gestion de l’information et les systèmes de théorie de la décision »\n",
    "> >\n",
    "> > Russell et Norvig (2020)\n",
    ">\n",
    "> > « Système basé sur une machine qui est conçu pour fonctionner avec différents niveaux d’autonomie et qui peut faire preuve d’adaptabilité après son déploiement, et qui, pour des objectifs explicites ou implicites, déduit, à partir des données qu’il reçoit, comment générer des résultats tels que des prédictions, du contenu, des recommandations ou des décisions qui peuvent influencer des environnements physiques ou virtuels »\n",
    "> >\n",
    "> > [AI Act européen](https://artificialintelligenceact.eu/fr/article/3/)\n",
    ">\n",
    "> Pour en apprendre plus sur ce sujet, voici une présentation que j’ai faite sur le sujet de l’IA en 2024:\n",
    ">\n",
    "> <details>\n",
    "> <summary><p>Dérouler les <em>slides</em> ou consulter celles-ci sur <a\n",
    "> href=\"https://linogaliana.github.io/20241015-prez-ia-masa/#/title-slide/\">plein\n",
    "> écran</a>{target=</p></summary>\n",
    "> <div class=\"sourceCode\">\n",
    "> <iframe class=\"sourceCode\" src=\"https://linogaliana.github.io/20241015-prez-ia-masa/#/title-slide/\"></iframe>\n",
    ">\n",
    "> </div>\n",
    "> </details>\n",
    ">\n",
    "> Enfin, la question est également pédagogique. Quand on parle d’IA depuis 2023, on pense à l’IA générative. Je pense que pour comprendre le fonctionnement de cette approche, radicalement différent d’autres paradigmes, et être capable de mettre en oeuvre des projets d’IA générative porteurs de valeur, il faut avoir des notions sur les apports et les limites de l’approche scientifique du *machine learning*. Sinon, on se retrouve à construire des usines à gaz pour des besoins simples ou à être incapables d’évaluer l’apport d’une approche générative par rapport à d’autres approches. Ce cours étant introductif, j’ai donc choisi de me concentrer sur le *machine learning* et du NLP basique, là encore à un niveau assez introductifs mais néanmoins déjà un peu creusés, et laisser aux curieux le soin de s’autoformer sur les sujets genIA.\n",
    "\n",
    "Néanmoins, il ne s’agit pas, par ces éléments, de rentrer dans la guéguerre stérile vs `Python`.\n",
    "Ces deux langages ayant beaucoup plus de points de convergence que de divergence, il est très simple de transposer les bonnes\n",
    "pratiques d’un langage à l’autre. Il s’agit d’un point qui est développé plus amplement dans le cours plus avancé que je donne avec Romain Avouac en dernière année d’ENSAE : [ensae-reproductibilite.github.io/website](https://ensae-reproductibilite.github.io/website).\n",
    "\n",
    "A terme, les data scientists et chercheurs en sciences sociales ou en économie utiliseront de manière presque indifférente, et en alternance, ou `Python`. Ce cours présentera ainsi régulièrement des analogies avec pour aider les\n",
    "personnes découvrant `Python`, mais connaissant déjà bien , à mieux comprendre certains messages.\n",
    "\n",
    "# 4. Pourquoi apprendre `Python` quand il existe des IA génératrices de code ?\n",
    "\n",
    "Les assistants de code, notamment `Copilot` et `ChatGPT`, ont changé à jamais le développement de code. Ces outils font maintenant parti des outils quotidiens des *data scientists* et offrent beaucoup de confort car ils peuvent, à l’aide d’instructions plus ou moins claires, générer du code `Python`. Et ces IA ayant étaient entraînées à partir de l’ensemble du code présent sur internet, et parfois spécialisées à répondre à des problèmes de développement, elles aident beaucoup. L’ambition du *vibe coding* est d’aller une étape plus loin dans ce processus en renforçant la prise d’initiative des LLM qui ne passerait plus par l’intermédiaire de l’humain pour accéder aux ressources de calcul qui permettent d’exécuter le code proposé.\n",
    "\n",
    "*Puisque maintenant les IA génèrent du code, pourquoi continuer à apprendre à coder ?*\n",
    "\n",
    "Car coder ce n’est pas juste produire des lignes de code, c’est se confronter à un problème, adopter une stratégie par étape pour y répondre, réfléchir à plusieurs solutions possibles et choisir la meilleure en arbitrant entre plusieurs objectifs (vitesse, simplicité, etc.), tester et corriger, etc. Le code est un outil au service d’un problème d’ingenieurie. Les IA savent très bien coder, elles savent relier un problème à des ressources sur lesquelles elles ont appris et savent bien transposer un problème rencontré dans un autre langage à `Python`.\n",
    "\n",
    "Mais encore faut-il savoir formuler le problème, savoir juger de la qualité de la réponse du LLM, être capable de remettre en question la proposition de l’assistant pour corriger une erreur ou obtenir une réponse plus satisfaisante. Les LLM sont une recherche *google* très raffinée: si vous n’avez pas les bons mots clés pour faire une recherche Google, votre recherche sera décevante. Il en va de même avec les LLM même si l’aspect conversationnel en langage naturel réduit la barrière à l’entrée.\n",
    "\n",
    "La confrontation à un jeu de données relève avant tout d’une démarche d’ingénierie. Le code n’est pas une fin en soi, mais un outil au service d’un raisonnement structuré, visant à résoudre un problème concret. Comme un ingénieur qui conçoit un pont à partir d’un besoin de traversée, le data scientist part d’un objectif opérationnel — construire un algorithme de sélection, mesurer l’impact d’un lancement produit, prédire une évolution de ventes — pour le formuler de manière exploitable. Cela implique de traduire des concepts scientifiques ou business en questions analytiques, puis de décomposer le problème en étapes logiques, chacune traduite en instructions que la machine peut exécuter.\n",
    "\n",
    "Dans ce cadre, un LLM peut jouer un rôle d’assistant, mais seulement si le problème est bien posé. Si les étapes sont floues ou mal définies, la réponse du modèle sera approximative, voire inutile. Sur une tâche standard, le résultat pourra sembler correct, mais sur une question plus spécifique, il faudra souvent affiner, reformuler, itérer… et parfois ne jamais obtenir de réponse satisfaisante. Non pas parce que le modèle est mauvais, mais parce que l’ingénierie du problème en amont fait toute la différence[4].\n",
    "\n",
    "Une dernière raison pour laquelle se contenter d’une IA de code sans recul critique est que ces dernières sont forcément en retard par rapport aux usages puisqu’elles ont été entraînées sur des données passées. L’écosystème `Python` est très dynamique et, même si les IA des principaux fournisseurs de services sont fréquemment réentrainées et peuvent maintenant accéder à internet pour rafraichir leurs connaissances, certaines librairies peuvent rapidement s’imposer dans leur domaine.\n",
    "\n",
    "Par exemple, en cette année 2025, [`uv`](https://docs.astral.sh/uv/) a connu une adoption rapide, comme [`ruff`](https://docs.astral.sh/ruff/) l’année d’avant. Il faudra encore un peu de temps pour que les IA génératives proposent d’elles-mêmes ce gestionnaire d’environnement plutôt que [`poetry`](https://python-poetry.org/). L’existence d’IA génératives ne dispense donc pas, comme avant, d’avoir une veille technique active et d’être vigilant sur l’évolution des pratiques.\n",
    "\n",
    "# 5. Objectifs du cours\n",
    "\n",
    "## 5.1 Initier à la démarche de la *data science*\n",
    "\n",
    "Ce cours s’adresse aux praticiens de la *data science*,\n",
    "discipline entendue ici au sens large comme la **combinaison de techniques issues des mathématiques, de la statistique et de l’informatique pour produire de la connaissance utile à partir de données**.\n",
    "Comme la *data science* n’est pas uniquement une discipline scientique mais vise également à fournir un ensemble d’outils pour répondre à des objectifs opérationnels, l’apprentissage du principal outil nécessaire à l’acquisition de connaissances en *data science*, à savoir le langage `Python`, est également\n",
    "l’occasion d’évoquer la démarche scientifique rigoureuse à adopter face à des données. Ce cours a pour objectif de présenter la démarche face à un jeu de données, les problèmes rencontrés, les solutions pour les surmonter et les implications que ces dernières peuvent avoir. Il ne s’agit donc pas que d’un cours sur un outil technique, désincarné de problématiques scientifiques.\n",
    "\n",
    "> **Faut-il avoir un *background* en mathématiques pour ce cours ?**\n",
    ">\n",
    "> Ce cours présuppose qu’on désire faire un usage de `Python` intense en données dans un cadre statistique rigoureux. Il ne revient que de manière secondaire sur les fondements statistiques ou algorithmiques derrière certaines des techniques évoquées, souvent l’objet d’enseignements dédiés, notamment à l’ENSAE.\n",
    ">\n",
    "> Ne pas connaître ces notions n’empêche ainsi pas de comprendre\n",
    "> le contenu de ce site *web* car les concepts plus avancés sont généralement présentés à part, dans des encadrés dédiés. La facilité d’usage de `Python` évite de devoir programmer soi-même un modèle, ce qui rend possible l’application de modèles dont on n’est pas expert. La connaissance des modèles sera plutôt nécessaire dans l’interprétation des résultats.\n",
    ">\n",
    "> Pour autant, même s’il est relativement facile d’utiliser des modèles complexes avec `Python`, il est fort utile d’avoir du recul sur ceux-ci avant de se lancer dans une démarche de modélisation. Il s’agit de l’une des raisons pour lesquelles la modélisation arrive si tardivement dans ce cours: en plus de faire appel à des concepts statistiques avancés, il est nécessaire, pour produire une modélisation pertinente, d’avoir appréhendé les faits stylisés dans nos données. Bien comprendre la structure des données et leur adéquation avec les hypothèses d’un modèle est indispensable pour construire une modélisation de qualité.\n",
    "\n",
    "## 5.2 Reproductibilité\n",
    "\n",
    "Ce cours donne une place centrale à la notion de reproductibilité. Cette exigence se traduit de diverses\n",
    "manières dans cet enseignement, en premier lieu en permettant que tous les exemples et exercices de ce cours soient testés par le biais de *notebooks* `Jupyter`[5].\n",
    "\n",
    "L’ensemble du contenu du site *web* est reproductible dans des environnements informatiques divers. Il est bien sûr possible de copier-coller les morceaux de code présents dans ce site, grâce au bouton présent au dessus\n",
    "des exemples de code:\n",
    "\n",
    "[1] [`Scikit Learn`](https://scikit-learn.org/stable/) est une librairie développée par les laboratoires de recherche publique français de l’INRIA depuis 2007. C’est un projet *open source* depuis le début. Le projet est désormais maintenu par [`:probabl.`](https://probabl.ai/), une *startup* dédiée à la gestion du projet *open source* `Scikit` et tout son écosystème associé qui rassemble une partie des équipes de recherche de l’INRIA qui a a participé au développement de l’écosystème incontournable du *machine learning*.\n",
    "\n",
    "[`Tensorflow`](https://www.tensorflow.org/) est une librairie initialement développée par Google pour leurs besoins internes, celle-ci a été rendue publique en 2015. Bien que moins de moins en moins utilisée, notamment du fait de la popularité de `PyTorch`, cette librairie a eu une influence importante dans les années 2010 en favorisant l’usage des réseaux de neurone dans la recherche ou pour l’exploitation à des fins opérationnelles.\n",
    "\n",
    "[`PyTorch`](https://pytorch.org/) est une librairie développée par Meta depuis 2018 et rattachée depuis 2022 à la [*PyTorch foundation*](https://pytorch.org/foundation). Il s’agit aujourd’hui du principal *framework* pour entraîner des réseaux de neurones.\n",
    "\n",
    "[2] Dans ces deux domaines, le concurrent le plus sérieux pour `Python`\n",
    "est `Javascript`. Néanmoins, la communauté autour de ce dernier langage est plus orientée\n",
    "autour des problématiques de développement web que de *data science*.\n",
    "\n",
    "[3] Les données tabulaires sont des données structurées, organisées, comme leur nom l’indique, sous forme de tableau permettant de mettre en correspondance des observations avec des variables. Cette structuration se distingue d’autres types de données plus complexes: textes libres, images, sons, vidéos… Dans le domaine des données\n",
    "non structurées, `Python` est le langage d’analyse hégémonique. Dans le domaine des données tabulaires, l’avantage compétitif de `Python` est moindre, notamment par rapport à , mais ces deux langages proposent un noyau de fonctionnalités assez similaires. Nous aurons l’occasion de régulièrement faire le parallèle entre ces deux langages lors des chapitres consacrés à la librairie `Pandas`.\n",
    "\n",
    "[4] Il n’est pas inutile sur ce sujet de lire le *post* de Thomas Wolf (CSO de `HuggingFace`) [“The Einstein AI model”](https://thomwolf.io/blog/scientific-ai.html). Même si le *post* évoque principalement les innovations de rupture en mettant quelque peu de côté les innovations marginales, il est intéressant de comprendre que les LLM, en dépit des grandes annonces prophétiques faites par les gourous de la tech, restent des outils qui certes ont de bonnes performances sur des tests standardisés mais restent des assistants, pour l’heure.\n",
    "\n",
    "[5] Un *notebook* est un environnement interactif qui permet d’écrire et d’exécuter du code en direct. Il combine, dans un seul document, du texte, du code qui peut être exécuté et dont les sorties s’affichent après calculs. C’est extrêmement pratique pour l’apprentissage du langage `Python`. Pour plus de détails, consultez la [documentation officielle de Jupyter](https://jupyter.org/documentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859c76b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"Essayez de me copier-coller\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a086b59-367f-45c8-9a4a-0e5a0bfb4138",
   "metadata": {},
   "source": [
    "Néanmoins, comme ce site présente de nombreux exemples, les allers et retours entre un environnement de test de `Python` et celui-ci pourraient être pénibles. Chaque chapitre est donc facilement récupérable sous forme de *notebook* `Jupyter` grâce à des boutons au début de chaque page. Voici, par exemple, ces boutons pour le premier chapitre consacré à `Pandas` :\n",
    "\n",
    "<div class=\"badge-container\"><a href=\"https://github.com/linogaliana/python-datascientist-notebooks/blob/main/notebooks/manipulation/02_pandas_intro.ipynb\" target=\"_blank\" rel=\"noopener\"><img src=\"https://img.shields.io/static/v1?logo=github&label=&message=View%20on%20GitHub&color=181717\" alt=\"View on GitHub\"></a>\n",
    "<a href=\"https://datalab.sspcloud.fr/launcher/ide/vscode-python?autoLaunch=true&name=«02_pandas_intro»&init.personalInit=«https%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmain%2Fsspcloud%2Finit-vscode.sh»&init.personalInitArgs=«manipulation%2002_pandas_intro%20correction»\" target=\"_blank\" rel=\"noopener\"><img src=\"https://custom-icon-badges.demolab.com/badge/SSP%20Cloud-Lancer_avec_VSCode-blue?logo=vsc&logoColor=white\" alt=\"Onyxia\"></a>\n",
    "<a href=\"https://datalab.sspcloud.fr/launcher/ide/jupyter-python?autoLaunch=true&name=«02_pandas_intro»&init.personalInit=«https%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmain%2Fsspcloud%2Finit-jupyter.sh»&init.personalInitArgs=«manipulation%2002_pandas_intro%20correction»\" target=\"_blank\" rel=\"noopener\"><img src=\"https://img.shields.io/badge/SSP%20Cloud-Lancer_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"></a>\n",
    "<a href=\"https://colab.research.google.com/github/linogaliana/python-datascientist-notebooks-colab//blob/main//notebooks/manipulation/02_pandas_intro.ipynb\" target=\"_blank\" rel=\"noopener\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a><br></div>\n",
    "\n",
    "Les recommandations concernant les environnements à privilégier pour utiliser ces notebooks sont reportées au prochain chapitre.\n",
    "\n",
    "L’exigence de reproductibilité se manifeste également\n",
    "dans le choix des exemples pris pour ce cours. L’ensemble du contenu de ce site s’appuie sur des données ouvertes, qu’il s’agisse de données françaises (principalement issues de la plateforme centralisatrice [`data.gouv`](https://www.data.gouv.fr) ou du site *web* de l’[Insee](https://www.insee.fr)) ou de données américaines. Les résultats sont donc reproductibles pour quelqu’un disposant d’un environnement identique[1].\n",
    "\n",
    "> **Note**\n",
    ">\n",
    "> Des chercheurs américains ont pu parler de crise de la reproductibilité dans le domaine du *machine learning* (Kapoor et Narayanan 2022). Les dérives de l’écosystème de\n",
    "> la publication scientifique et les enjeux économiques derrière les publications académiques dans le domaine du *machine learning* ont une place privilégiée parmi les facteurs pouvant l’expliquer.\n",
    ">\n",
    "> Néanmoins, l’enseignement universitaire porte également une responsabilité dans ce domaine. Les étudiants et chercheurs ne sont pas formés à ces sujets et s’ils n’adoptent pas cette exigence tôt dans leur parcours, ils n’y seront plus forcément incités ultérieurement. Pour cette raison, en plus de former à `Python` et à la *data science*, ce cours introduit à l’usage du logiciel de contrôle de version `Git` dans une partie dédiée.\n",
    ">\n",
    "> Tous les projets des élèves doivent être *open source*, ce qui est l’une des meilleures manières, pour un enseignant, de trouver une consigne pour que les élèves produisent un code de qualité.\n",
    "\n",
    "## 5.3 Évaluation\n",
    "\n",
    "Les élèves de l’ENSAE valident le cours grâce à\n",
    "un projet approfondi. Les éléments relatifs à l’évaluation du cours, ainsi qu’une liste des projets déjà effectués, sont disponibles dans la section [Évaluation](../../content/annexes/evaluation).\n",
    "\n",
    "# 6. Plan du cours\n",
    "\n",
    "Ce cours est une introduction aux enjeux de la *data science* à\n",
    "travers l’apprentissage du langage `Python`. Comme le terme *“data science”*\n",
    "l’indique, une partie importante de ce cours est consacrée au travail sur les\n",
    "données: récupération, structuration, exploration, mise en relation.\n",
    "\n",
    "C’est l’objet de la première partie du cours [“Manipuler des données”](../../content/manipulation/index.qmd) qui sert de fondement au reste du cours. Malheureusement, de nombreuses formations en *data science*, statistiques appliquées ou sciences économiques et sociales, font l’impasse sur cette part du travail des *data scientists* - qu’on appelle parfois [“data wrangling”](https://en.wikipedia.org/wiki/Data_wrangling) ou [*“feature engineering”*](https://en.wikipedia.org/wiki/Feature_engineering) - qui, en plus de représenter une part importante du temps de travail des *data scientists*, est indispensable pour construire un modèle pertinent.\n",
    "\n",
    "L’objectif de cette partie est d’illustrer les enjeux liés à la récupération de plusieurs types de sources de données et à leur exploitation par le biais de `Python`. Les exemples seront diversifiés, pour illustrer la richesse des données qui peuvent être analysées avec `Python`: statistiques d’émissions communales de $CO_2$ en France, données de transactions immobilières, diagnostics énergétiques des logements, données de fréquentation des stations vélib…\n",
    "\n",
    "La deuxième partie est consacrée à la production de visualisations avec `Python`. Après avoir récupéré et nettoyé des données, on désire généralement synthétiser celles-ci par le biais de tableaux, de productions graphiques ou de cartes. Cette partie est une introduction rapide à ce sujet ([“Communiquer avec `Python`”](../../content/visualisation/index.qmd)). Assez introductive, l’objectif de cette partie est surtout de donner quelques notions qui sont consolidées par la suite.\n",
    "\n",
    "La troisième partie est consacrée à la modélisation à travers l’exemple fil rouge de la science électorale ([“Modéliser avec `Python`”](../../content/modelisation/index.qmd)). L’objectif de cette partie est d’illustrer la démarche scientifique du *machine learning*, les choix méthodologiques et techniques afférents et ouvrir vers les enjeux suivants qui seront évoqués dans la suite du cursus universitaire.\n",
    "\n",
    "La quatrième partie du cours fait un pas de côté pour se consacrer aux enjeux spécifiques liés à l’exploitation des données textuelles. Il s’agit du chapitre d’[“Introduction au *Natural Language Processing (NLP)”* avec `Python`”](../../content/NLP/index.qmd). Ce champ de recherche étant particulièrement actif, il ne s’agit que d’une introduction au sujet. Pour aller plus loin, se référer à Russell et Norvig (2020), chapitre 24.\n",
    "\n",
    "Ce chapitre propose aussi une partie consacrée au contrôle de version avec le logiciel `Git` ([Découvrir `Git`](../../content/git/index.qmd)). Pourquoi proposer ce contenu dans le cadre d’un cours de `Python` ? Car apprendre `Git` permettra de produire de meilleurs codes `Python`, de les échanger, voire même de les tester dans des environnements reproductibles ou de mettre à disposition les résultats en ligne (c’est une utilisation plus avancée, objet du cours de [mise en production](https://ensae-reproductibilite.github.io/)). Ce pas de côté dans l’apprentissage de `Python` est très utile, *a fortiori* dans un monde où [`Github`](https://github.com/) sert de vitrine et où les entreprises et administrations exigent, à juste titre, que leurs *data scientists* sachent faire du `Git`.\n",
    "\n",
    "# Références\n",
    "\n",
    "Davenport, Thomas H, et DJ Patil. 2012. « Data scientist, the sexiest job of the 21st century ». *Harvard business review* 90 (5): 70‑76. <https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century>.\n",
    "\n",
    "———. 2022. « Is data scientist still the sexiest job of the 21st century? » *Harvard Business Review* 90.\n",
    "\n",
    "Kapoor, Sayash, et Arvind Narayanan. 2022. « Leakage and the Reproducibility Crisis in ML-based Science ». arXiv. <https://doi.org/10.48550/ARXIV.2207.07048>.\n",
    "\n",
    "Russell, Stuart J., et Peter Norvig. 2020. *Artificial Intelligence: A Modern Approach (4th Edition)*. Pearson. <http://aima.cs.berkeley.edu/>.\n",
    "\n",
    "[1] Le fait d’ouvrir les chapitres sous la forme de *notebooks* dans des environnements standardisés, ce qui sera proposé à partir du prochain chapitre, permet d’assurer que vous disposiez d’un environnement contrôlé. Les installations personnelles de `Python` ont toutes les chances d’avoir subies des bidouillages modifiant votre environnement et pouvant provoquer des erreurs inattendues et difficiles à comprendre: ce n’est donc pas un usage recommandé pour ce cours. Comme vous pourrez le découvrir dans le prochain chapitre, les environnements *cloud* offrent un confort en ce qui concerne la standardisation des environnements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3",
   "path": "/home/runner/work/python-datascientist/python-datascientist/.venv/share/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": "3"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
